{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T10:37:24.328992Z",
     "start_time": "2021-02-19T10:37:23.514959Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from os import path\n",
    "from IPython.display import Video\n",
    "\n",
    "from utils import *\n",
    "from pre_processing import *\n",
    "from change_detection import *\n",
    "from object_classification import *\n",
    "from post_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(file_name ,nf1):\n",
    "    cap = cv2.VideoCapture(file_name)\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame_num = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "            gray = cv2.cvtColor(frame, cv2.IMREAD_COLOR)\n",
    "            if int(frame_num) == nf1:\n",
    "                f1 = gray\n",
    "                return f1\n",
    "            cv2.waitKey(30)\n",
    "        else:\n",
    "            return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_image = get_frames('data/videos/approved1.mp4', 162)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('data/preprocessing_images/image6.jpg', pre_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T10:37:28.361509Z",
     "start_time": "2021-02-19T10:37:28.356321Z"
    }
   },
   "outputs": [],
   "source": [
    "video_name = 'approved1'\n",
    "video_path = path.join('data', 'videos', f'{video_name}.mp4')\n",
    "video_det_path = path.join('data', 'detected_videos', f'{video_name}.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T10:37:30.044810Z",
     "start_time": "2021-02-19T10:37:28.844259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"data\\videos\\approved1.mp4\" controls  width=\"600\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid = load_video(video_path=video_path)\n",
    "Video(video_path, height=400, width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'C:\\\\Users\\\\alon2\\\\Desktop\\\\CV_Final\\\\utils.py'>"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import object_classification, utils\n",
    "import importlib\n",
    "importlib.reload(object_classification)\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Histograms Calculation\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessed images outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = \"data/object_outline/\"\n",
    "image_list = utils.load_images(images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the outline histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 15\n",
    "histograms_mean_dict = {\"RED\":[], \"GREEN\":[], \"BLUE\":[]}\n",
    "for img_num, img in enumerate(image_list):\n",
    "    r_histograms_mean_list = object_classification.generate_patches_histograms_mean(img[:,:,0], window_size)\n",
    "    g_histograms_mean_list = object_classification.generate_patches_histograms_mean(img[:,:,1], window_size)\n",
    "    b_histograms_mean_list = object_classification.generate_patches_histograms_mean(img[:,:,2], window_size)\n",
    "    histograms_mean_dict[\"RED\"].append(r_histograms_mean_list)\n",
    "    histograms_mean_dict[\"GREEN\"].append(g_histograms_mean_list)\n",
    "    histograms_mean_dict[\"BLUE\"].append(b_histograms_mean_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering the hitograms mean and calculating the mean for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 2\n",
    "allowed_histogram_means = object_classification.calculate_allowed_histograms_means(histograms_mean_dict, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RED': [145.97060582144468, 171.66362499999997],\n",
       " 'GREEN': [146.68428421481053, 173.34629166666656],\n",
       " 'BLUE': [139.02536768604205, 166.758625]}"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_histogram_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Object Size calculation\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a grid of the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = \"data/preprocessing_images/\"\n",
    "image_to_grid = utils.load_images(images_path)[0] # taking the first image based on the knowledge all images sizes are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 5 # grid the image with boxes of 20X20\n",
    "image_x_grid = np.arange(0, image_to_grid.shape[1], grid_size)\n",
    "image_y_grid = np.arange(0, image_to_grid.shape[0], grid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a database for approved object size information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_object_location = [100, 325, 260, 360]\n",
    "object_size_info = object_classification.get_grids(image_x_grid, image_y_grid, first_object_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'middle_grid': [42.5, 62.0],\n",
       " 'grid_size': 836,\n",
       " 'grid_coordinates': {'X': (array([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
       "          38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
       "          55, 56, 57, 58, 59, 60, 61, 62, 63, 64], dtype=int64),),\n",
       "  'Y': (array([53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69,\n",
       "          70, 71], dtype=int64),)}}"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_size_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_approved_object_info = {\"RED\": allowed_histogram_means[\"RED\"],\n",
    "                             \"GREEN\": allowed_histogram_means[\"GREEN\"],\n",
    "                             \"BLUE\": allowed_histogram_means[\"BLUE\"],\n",
    "                             \"location\": [object_size_info]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RED': [145.97060582144468, 171.66362499999997],\n",
       " 'GREEN': [146.68428421481053, 173.34629166666656],\n",
       " 'BLUE': [139.02536768604205, 166.758625],\n",
       " 'location': [{'middle_grid': [42.5, 62.0],\n",
       "   'grid_size': 836,\n",
       "   'grid_coordinates': {'X': (array([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
       "            38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
       "            55, 56, 57, 58, 59, 60, 61, 62, 63, 64], dtype=int64),),\n",
       "    'Y': (array([53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69,\n",
       "            70, 71], dtype=int64),)}}]}"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_approved_object_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T10:37:40.205390Z",
     "start_time": "2021-02-19T10:37:31.921261Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "det_vid = change_dection(vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T10:38:32.883622Z",
     "start_time": "2021-02-19T10:38:30.674017Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-377-1616d6e271f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplay_video_by_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdet_vid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\alon2\\Desktop\\CV_Final\\utils.py\u001b[0m in \u001b[0;36mplay_video_by_images\u001b[1;34m(video, frame_rate)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mframe_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRate\u001b[0m \u001b[0mof\u001b[0m \u001b[0mframes\u001b[0m \u001b[0mto\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mframe_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframe_index\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mframe_rate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "play_video_by_images(det_vid, frame_rate=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T10:37:41.544428Z",
     "start_time": "2021-02-19T10:37:40.207936Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-378-3613dbab46b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdet_vid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideo_det_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Video(video_det_path, height=400, width=600)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\alon2\\Desktop\\CV_Final\\utils.py\u001b[0m in \u001b[0;36msave_video\u001b[1;34m(video, output_path)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFull\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0msave\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvideo\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mincluding\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \"\"\"\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "save_video(det_vid, video_det_path)\n",
    "# Video(video_det_path, height=400, width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import image got from change detection phase\n",
    "detected_images = \"data/object_classification/\"\n",
    "loaded_detected_images = utils.load_images(detected_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_objects = [{'object1': [520, 660, 260, 320], 'object2': [860, 1040, 470, 590],\n",
    "                    'object3':[600, 800, 0, 130], 'object4': [1040, 1120, 130, 270]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, img in enumerate(loaded_detected_images):\n",
    "    detected_objects_location = detected_objects[idx]\n",
    "    num_of_objects = len(detected_objects_location)\n",
    "    objects_info = object_classification.get_detected_objects_info(img, detected_objects_location, image_x_grid, image_y_grid, window_size)\n",
    "    approved_objects = object_classification.match_with_approved_objects(num_of_objects, objects_info, first_approved_object_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object2 is approved\n"
     ]
    }
   ],
   "source": [
    "for i in approved_objects:\n",
    "    if f\"object{i+1}\" in detected_objects[0].keys():\n",
    "        print(f\"object{i+1} is approved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# save the image with red squares wrapping the unapproved objects and blue squares wrapping approved objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
